{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "#from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Reorg_g</th>\n",
       "      <th>Reorg_ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>CC[C@H]1CCCCN1C(=O)[C@@H](C)OC(=O)c1c(C)oc(-n2...</td>\n",
       "      <td>0.631486</td>\n",
       "      <td>0.535060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>O[C@@H](CNC1CC1)CN1CCc2sccc2C1</td>\n",
       "      <td>0.825901</td>\n",
       "      <td>1.116781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>N#CCCNC(=O)[C@@]1(O)CCSC1</td>\n",
       "      <td>1.463943</td>\n",
       "      <td>0.964848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>COC[C@H]1CN(c2ccc(OCC[C@@H](C)O)cc2)C(=O)O1</td>\n",
       "      <td>0.166669</td>\n",
       "      <td>0.161458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>N#Cc1c(-c2ccccc2OCC(N)=O)[nH]c(C(N)=O)c1N</td>\n",
       "      <td>0.313820</td>\n",
       "      <td>0.338862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                             SMILES   Reorg_g  \\\n",
       "0  train_0  CC[C@H]1CCCCN1C(=O)[C@@H](C)OC(=O)c1c(C)oc(-n2...  0.631486   \n",
       "1  train_1                     O[C@@H](CNC1CC1)CN1CCc2sccc2C1  0.825901   \n",
       "2  train_2                          N#CCCNC(=O)[C@@]1(O)CCSC1  1.463943   \n",
       "3  train_3        COC[C@H]1CN(c2ccc(OCC[C@@H](C)O)cc2)C(=O)O1  0.166669   \n",
       "4  train_4          N#Cc1c(-c2ccccc2OCC(N)=O)[nH]c(C(N)=O)c1N  0.313820   \n",
       "\n",
       "   Reorg_ex  \n",
       "0  0.535060  \n",
       "1  1.116781  \n",
       "2  0.964848  \n",
       "3  0.161458  \n",
       "4  0.338862  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_set.ReorgE.csv\")\n",
    "train.columns = [\"index\", \"SMILES\", \"Reorg_g\", \"Reorg_ex\"]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"ex_file\"):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(\"ex_file\")\n",
    "\n",
    "if os.path.isdir(\"g_file\"):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(\"g_file\")\n",
    "\n",
    "train_mol = sorted(glob(\"data/mol_files/train_set/*.mol\"))\n",
    "print(train_mol[0:100])\n",
    "\n",
    "\n",
    "\n",
    "count=0\n",
    "for i in train_mol:\n",
    "    result = []\n",
    "    tmp = open(i, 'r').read().split(\"\\n\")\n",
    "    #print(tmp)\n",
    "    #count +=1\n",
    "    #if count ==100:\n",
    "    #    break\n",
    "    print(len(tmp))\n",
    "    for j in tmp:\n",
    "        print(count)\n",
    "        count+=1\n",
    "        tmp_ = re.sub(' +', ' ', j.lstrip()).split(' ')#j.lstrip==> j에서 왼쪽 공백을 지운 문자열  ' +'문자를 ' '로 치환\n",
    "        #print('check')\n",
    "        if len(tmp_) > 11:\n",
    "            result.append(tmp_)\n",
    "            \n",
    "    file_name = i.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    if \"ex\" in file_name: #분자 내 원자 위치와 정보를 가지는 csv 파일을 만들어 냄\n",
    "        pd.DataFrame(result).to_csv(f\"ex_file/{file_name}\" + \".csv\", index = False)\n",
    "    elif \"g\" in file_name:\n",
    "        pd.DataFrame(result).to_csv(f\"g_file/{file_name}\" + \".csv\", index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18157/18157 [00:27<00:00, 652.32it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "error = []\n",
    "g_data, ex_data = [], []\n",
    "mol = []\n",
    "\n",
    "for i in tqdm(train[train.columns[0]]):\n",
    "    tmp_g = pd.read_csv(f\"g_file/{i}\" + '_g.csv')\n",
    "\n",
    "    if len(tmp_g) >= max_len:\n",
    "        max_len = len(tmp_g)\n",
    "        \n",
    "    for j in tmp_g[\"3\"]: #어떤 원자인지 C,H,,N,O 등!! 이유는 해당 데이터셋에 등장하는 모든 원소를 추가하기 위함\n",
    "        mol.append(j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'C', 'I', 'Br', 'H', 'Si', 'B', 'P', 'Cl', 'F', 'N', 'O']\n"
     ]
    }
   ],
   "source": [
    "mol_list = list(set(mol)) #원소의 중복제거=> 즉 등장하는 원소들의 종류가 mol_list가 된다\n",
    "print(mol_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18157/18157 [01:17<00:00, 233.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#mol_list = list(set(mol)) #원소의 중복제거=> 즉 등장하는 원소들의 종류가 mol_list가 된다\n",
    "\n",
    "g_data, ex_data = [], [] #바닥 상태 데이터와 들뜬 상태 데이터의 리스트 \n",
    "\n",
    "def get_mol(data):\n",
    "    if data in mol_list:\n",
    "        return mol_list.index(data) + 1 #고유 라벨 +1 값을 \n",
    "    # 'S' : 1, 'C' :2, 'I' : 3, 'Br': 4, 'H': 5, 'Si : 6', 'B' : 7, 'P' : 8 , 'Cl' : 9, 'F' : 10, 'N' : 11, 'O' : 12\n",
    "    \n",
    "    else: #해당 원소가 없다면 -1 리턴 ==> 일단 없을리는 없음 , 예외처리\n",
    "        return -1\n",
    "\n",
    "for i in tqdm(train[train.columns[0]]):\n",
    "    tmp_g = pd.read_csv(f\"g_file/{i}\" + '_g.csv').iloc[:, :4]   #바닥 상태에서 원자에서 0부터 3까지 가져오는데, 해당 원소의 x,y,z 위치와 원소 정보\n",
    "    tmp_ex = pd.read_csv(f\"ex_file/{i}\" +'_ex.csv').iloc[:, :4]   #들뜬 상태에서 원자에서 0부터 3까지 가져오는데, 해당 원소의 x,y,z 위치와 원소 정보\n",
    "    \n",
    "    tmp_g[\"3\"] = tmp_g[\"3\"].apply(lambda x : get_mol(x))  #원소기호를 가져와 해당하는 인덱스로 변환\n",
    "    tmp_ex[\"3\"] = tmp_ex[\"3\"].apply(lambda x : get_mol(x))  #원소기호를 가져와 해당하는 인덱스로 변환\n",
    "    \n",
    "    tmp_g = np.array(tmp_g)  #읽어온 csv파일의 값을 numpy array 형식으로 변환해줌  \n",
    "    tmp_ex = np.array(tmp_ex)  #읽어온 csv파일의 값을 numpy array 형식으로 변환해줌  \n",
    "     \n",
    "    if max_len != len(tmp_g):  #해당 분자의 원소 수가 전체 데이터 셋중 가장 큰 원소를 가진 개수와 다르다면  빈칸을 0으로 채움 \n",
    "        tmp_g = np.concatenate((tmp_g, np.array([[0] * 4] * (max_len-tmp_g.shape[0]))))\n",
    "        tmp_ex = np.concatenate((tmp_ex, np.array([[0] * 4] * (max_len - tmp_ex.shape[0]))))\n",
    "        ?\"\"\n",
    "        \n",
    "    elif max_len == len(tmp_g): #해당 길이가 최대길이와 같다면\n",
    "        tmp_g = tmp_g\n",
    "        tmp_ex = tmp_ex\n",
    "    \n",
    "    g_data.append(tmp_g)\n",
    "    ex_data.append(tmp_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18157, 1240)\n",
      "(18157, 1240)\n",
      "(18157, 2480)\n",
      "(18157, 2)\n"
     ]
    }
   ],
   "source": [
    "g_data = np.array(g_data).reshape(len(g_data), -1)\n",
    "ex_data = np.array(ex_data).reshape(len(ex_data), -1)\n",
    "print(g_data.shape)\n",
    "print(ex_data.shape)\n",
    "train_x = np.concatenate((g_data, ex_data), axis = 1)\n",
    "train_y = np.array(train.loc[:, [\"Reorg_g\", \"Reorg_ex\"]])\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.8972, -2.3256,  0.4309, ...,  0.    ,  0.    ,  0.    ],\n",
       "       [ 2.2446,  2.0206, -0.4231, ...,  0.    ,  0.    ,  0.    ],\n",
       "       [ 4.8695, -1.9497, -5.1308, ...,  0.    ,  0.    ,  0.    ],\n",
       "       ...,\n",
       "       [ 1.423 , -0.1053,  0.7295, ...,  0.    ,  0.    ,  0.    ],\n",
       "       [11.486 ,  1.9573,  5.8098, ...,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.6476,  0.2797,  0.0464, ...,  0.    ,  0.    ,  0.    ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = MultiOutputRegressor(lgb.LGBMRegressor(random_state=42, n_estimators=1000, max_depth=61, learning_rate=0.075)).fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 914/914 [00:01<00:00, 519.67it/s]\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"test_ex_file\"):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(\"test_ex_file\")\n",
    "\n",
    "if os.path.isdir(\"test_g_file\"):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(\"test_g_file\")\n",
    "\n",
    "test_mol = sorted(glob(\"data/mol_files/test_set/*.mol\"))\n",
    "\n",
    "for i in tqdm(test_mol):\n",
    "    result = []\n",
    "    tmp = open(i, 'r').read().split(\"\\n\")\n",
    "    for j in tmp:\n",
    "        tmp_ = re.sub(' +', ' ', j.lstrip()).split(' ')\n",
    "        if len(tmp_) > 11:\n",
    "            result.append(tmp_)\n",
    "\n",
    "    file_name = i.split('/')[-1].split('.')[0]\n",
    "\n",
    "    if \"ex\" in file_name:\n",
    "        pd.DataFrame(result).to_csv(f\"test_ex_file/{file_name}\" + \".csv\", index = False)\n",
    "    elif \"g\" in file_name:\n",
    "        pd.DataFrame(result).to_csv(f\"test_g_file/{file_name}\" + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 457/457 [00:01<00:00, 230.71it/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test_set.csv\")\n",
    "\n",
    "test_g, test_ex = [], []\n",
    "\n",
    "for i in tqdm(test[test.columns[0]]):\n",
    "    tmp_g = pd.read_csv(f\"test_g_file/{i}\" + '_g.csv').iloc[:, :4]\n",
    "    tmp_ex = pd.read_csv(f\"test_ex_file/{i}\" +'_ex.csv').iloc[:, :4]\n",
    "    \n",
    "    tmp_g[\"3\"] = tmp_g[\"3\"].apply(lambda x : get_mol(x))\n",
    "    tmp_ex[\"3\"] = tmp_ex[\"3\"].apply(lambda x : get_mol(x))\n",
    "    \n",
    "    tmp_g = np.array(tmp_g)\n",
    "    tmp_ex = np.array(tmp_ex)\n",
    "    \n",
    "    if len(tmp_g) < max_len:\n",
    "        tmp_g = np.concatenate((tmp_g, np.array([[0] * 4] * (max_len-tmp_g.shape[0]))))\n",
    "        tmp_ex = np.concatenate((tmp_ex, np.array([[0] * 4] * (max_len - tmp_ex.shape[0]))))\n",
    "    elif len(tmp_g) == max_len:\n",
    "        pass\n",
    "    else:\n",
    "        tmp_g = tmp_g[:max_len]\n",
    "        tmp_ex = tmp_ex[:max_len]\n",
    "    \n",
    "    test_g.append(tmp_g)\n",
    "    test_ex.append(tmp_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457, 2480)\n"
     ]
    }
   ],
   "source": [
    "test_g = np.array(test_g).reshape(len(test_g), -1)\n",
    "test_ex = np.array(test_ex).reshape(len(test_ex), -1)\n",
    "\n",
    "test_x = np.concatenate((test_g, test_ex), axis = 1)\n",
    "\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = LR.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Reorg_g</th>\n",
       "      <th>Reorg_ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Reorg_g  Reorg_ex\n",
       "0  test_0        0         0\n",
       "1  test_1        0         0\n",
       "2  test_2        0         0\n",
       "3  test_3        0         0\n",
       "4  test_4        0         0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[:, [\"Reorg_g\", \"Reorg_ex\"]] = pred\n",
    "\n",
    "submission.to_csv(\"SAMSUNG_BASELINE.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('ENVC3D')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4143b59433526a7d55b89e9a8a4e22d7e9615efa2c5a2ad2d0880a8538ea463f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
