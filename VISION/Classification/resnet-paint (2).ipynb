{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm, trange\nimport random\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nfrom collections import OrderedDict\nfrom time import time, ctime, localtime\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset,DataLoader\nfrom sklearn.model_selection import train_test_split\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.image as mpimg\nfrom torchvision import datasets\nfrom torchvision import models\nimport  cv2\nimport time\nimport glob\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split,train_test_split\nfrom sklearn.model_selection import StratifiedKFold,  KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-06T03:47:59.872508Z","iopub.execute_input":"2022-06-06T03:47:59.873007Z","iopub.status.idle":"2022-06-06T03:48:00.936749Z","shell.execute_reply.started":"2022-06-06T03:47:59.872969Z","shell.execute_reply":"2022-06-06T03:48:00.935934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:00.938646Z","iopub.execute_input":"2022-06-06T03:48:00.93892Z","iopub.status.idle":"2022-06-06T03:48:00.980797Z","shell.execute_reply.started":"2022-06-06T03:48:00.938885Z","shell.execute_reply":"2022-06-06T03:48:00.979926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#본인 컴퓨터에 맞는 train folder의 위치를 입력합니다.(string)\ntrain_dir = '../input/paint-dataset/painting_resize_256/train' \ntest_dir = '../input/paint-dataset/painting_resize_256/test'","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:00.982026Z","iopub.execute_input":"2022-06-06T03:48:00.982989Z","iopub.status.idle":"2022-06-06T03:48:00.990339Z","shell.execute_reply.started":"2022-06-06T03:48:00.982949Z","shell.execute_reply":"2022-06-06T03:48:00.989607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 폴더의 목록(화가의 이름)을 가지고 옵니다. 총 class : 15개  \nclasses = []\n#class목록을 저장할 list \nfor i in range(len(glob.glob(train_dir+'/*'))):\n    classes.append(glob.glob(train_dir+'/*')[i].split('/')[-1])\nclass_num = len(classes)\nprint('Total Class num: ',class_num)\nprint('Class label:')\nfor i in range(class_num):print('{:5d}th : ' .format(i+1),classes[i])","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:00.993055Z","iopub.execute_input":"2022-06-06T03:48:00.993331Z","iopub.status.idle":"2022-06-06T03:48:01.015235Z","shell.execute_reply.started":"2022-06-06T03:48:00.993297Z","shell.execute_reply":"2022-06-06T03:48:01.014515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_Image(image_path,transform =None):\n    image = Image.open(image_path).convert(\"RGB\")\n    if transform ==None:\n        return image\n    else: return transform(image)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.016379Z","iopub.execute_input":"2022-06-06T03:48:01.016707Z","iopub.status.idle":"2022-06-06T03:48:01.021669Z","shell.execute_reply.started":"2022-06-06T03:48:01.016669Z","shell.execute_reply":"2022-06-06T03:48:01.020895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = \"../input/paint-dataset/painting_resize_256/train/Andy_Warhol/Andy_Warhol_1.jpg\"\ncheck_Image(image)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.023003Z","iopub.execute_input":"2022-06-06T03:48:01.023723Z","iopub.status.idle":"2022-06-06T03:48:01.067894Z","shell.execute_reply.started":"2022-06-06T03:48:01.023686Z","shell.execute_reply":"2022-06-06T03:48:01.067115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_path = '../input/paint-dataset/painting_resize_256/train'\npainters = os.listdir(train_data_path)\npainters.sort()\nprint(painters)\ntrain_all_pictures = []\nweighted_num = [0]\nfor painter in painters:\n    train_all_pictures += glob.glob(train_data_path+ '/'+ painter+'/*.jpg' )\n    weighted_num.append(len(glob.glob(train_data_path+ '/'+ painter+'/*.jpg' )))\ntrain_all_pictures.sort()\nprint(len(train_all_pictures))    \n\n\ntest_data_path = '../input/paint-dataset/painting_resize_256/test'\ntest_all_pictures =[]\ntest_all_pictures += glob.glob(test_data_path+ '/*.jpg' )\n    \nprint(len(test_all_pictures))    \nprint(weighted_num)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.069025Z","iopub.execute_input":"2022-06-06T03:48:01.069284Z","iopub.status.idle":"2022-06-06T03:48:01.122428Z","shell.execute_reply.started":"2022-06-06T03:48:01.069247Z","shell.execute_reply":"2022-06-06T03:48:01.121586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame()\ntest_df =pd.DataFrame()\n\ntrain_df['file_name'] = train_all_pictures\ntest_files = glob.glob('../input/paint-dataset/painting_resize_256/test/*.jpg')\n\ntest_files.sort()\ntest_df['file_name'] = test_files\n#print(test_files)\ntrain_all_pictures[0].split('/')[-2]\nfor picture in train_all_pictures:\n    print('painter is '+picture.split('/')[-2])","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.123735Z","iopub.execute_input":"2022-06-06T03:48:01.124245Z","iopub.status.idle":"2022-06-06T03:48:01.554926Z","shell.execute_reply.started":"2022-06-06T03:48:01.124207Z","shell.execute_reply":"2022-06-06T03:48:01.554212Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for painter in painters:\n    train_df[painter] = 0\nsum_number=0    \nfor i in range(len(painters)):\n    print(sum_number , ' ', sum_number+ weighted_num[i+1])\n    train_df[sum_number:sum_number+weighted_num[i+1]][painters[i]]  =1 \n    sum_number +=weighted_num[i+1]\n#train_df[0:262]['Albrecht_Du_rer'] =1\n\ntrain_df\n#train_df.to_csv('../input/paint-dataset/Sample.csv', index = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.556253Z","iopub.execute_input":"2022-06-06T03:48:01.556519Z","iopub.status.idle":"2022-06-06T03:48:01.597834Z","shell.execute_reply.started":"2022-06-06T03:48:01.556482Z","shell.execute_reply":"2022-06-06T03:48:01.597143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = train_df.loc[:, painters[0]:painters[14]]\nlabel = label.values\nx = np.argmax(label,axis=1)\nprint(len(x))\ntrain_df['class'] = x\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.600219Z","iopub.execute_input":"2022-06-06T03:48:01.600655Z","iopub.status.idle":"2022-06-06T03:48:01.626668Z","shell.execute_reply.started":"2022-06-06T03:48:01.600618Z","shell.execute_reply":"2022-06-06T03:48:01.62596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, valid_df = train_test_split(train_df,test_size=0.2,shuffle=True,stratify=train_df['class'])\ntrain_label = train_df.loc[:, painters[0]:painters[14]]\nvalid_label = valid_df.loc[:,painters[0]:painters[14]]\ntrain_df.reset_index(drop=True,inplace=True)\ntrain_label.reset_index(drop=True,inplace=True)\nvalid_df.reset_index(drop=True,inplace=True)\nvalid_label.reset_index(drop=True,inplace=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.628041Z","iopub.execute_input":"2022-06-06T03:48:01.628525Z","iopub.status.idle":"2022-06-06T03:48:01.654352Z","shell.execute_reply.started":"2022-06-06T03:48:01.628488Z","shell.execute_reply":"2022-06-06T03:48:01.653633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.655801Z","iopub.execute_input":"2022-06-06T03:48:01.656258Z","iopub.status.idle":"2022-06-06T03:48:01.674775Z","shell.execute_reply.started":"2022-06-06T03:48:01.656222Z","shell.execute_reply":"2022-06-06T03:48:01.674016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Paint_dataset(Dataset):\n    \n    def __init__(self,df,data_dir,transform,train=True,label=None):\n        self.len = df.shape[0]\n        self.dir = data_dir\n        self.transform=transform\n        self.df = df\n        self.train=train\n        self.label=label\n        \n    def __len__(self):\n        return self.len\n    \n    def __getitem__(self,idx):\n        img_pth = self.df['file_name'].loc[idx]\n        image = mpimg.imread(img_pth)\n        image = cv2.resize(image,(224,224))\n        if self.transform:\n            image = self.transform(image)\n        if(self.train==True):\n            labels =np.argmax(self.label.loc[idx,:].values)\n        else:\n            return image\n        return image,labels\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.676178Z","iopub.execute_input":"2022-06-06T03:48:01.676743Z","iopub.status.idle":"2022-06-06T03:48:01.684946Z","shell.execute_reply.started":"2022-06-06T03:48:01.676704Z","shell.execute_reply":"2022-06-06T03:48:01.68412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\ntrain_transf = transforms.Compose([transforms.ToPILImage(),\n                                   transforms.ToTensor(),normalize])\n\nvalid_transf = transforms.Compose([transforms.ToPILImage(),\n                                  transforms.ToTensor(),normalize])\ntest_transf = transforms.Compose([transforms.ToPILImage(),\n                                  transforms.ToTensor(),normalize])","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.685929Z","iopub.execute_input":"2022-06-06T03:48:01.686166Z","iopub.status.idle":"2022-06-06T03:48:01.695441Z","shell.execute_reply.started":"2022-06-06T03:48:01.686142Z","shell.execute_reply":"2022-06-06T03:48:01.694446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = Paint_dataset(train_df,train_dir,transform=train_transf,train=True,label=train_label)\nvalid_dataset = Paint_dataset(valid_df,train_dir,transform=valid_transf,train=True,label=valid_label)\ntest_dataset = Paint_dataset(test_df,test_dir,transform=test_transf,train=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.698842Z","iopub.execute_input":"2022-06-06T03:48:01.700682Z","iopub.status.idle":"2022-06-06T03:48:01.705901Z","shell.execute_reply.started":"2022-06-06T03:48:01.700649Z","shell.execute_reply":"2022-06-06T03:48:01.704948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = train_df.columns\nfig = plt.figure(figsize=(25, 8))\nfor i, idx in enumerate(np.random.choice(train_df.index, 10)):\n    ax = fig.add_subplot(2, 10//2, i+1, xticks=[], yticks=[])\n    pth = train_df.file_name[idx]\n    im = mpimg.imread(pth)\n    im = cv2.resize(im, (100, 100)) \n    plt.imshow(im, cmap=\"hot\")\n    lab =col[np.argmax(train_df.loc[idx, painters].values)+1]\n    ax.set_title(lab)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:01.732898Z","iopub.execute_input":"2022-06-06T03:48:01.733218Z","iopub.status.idle":"2022-06-06T03:48:02.455992Z","shell.execute_reply.started":"2022-06-06T03:48:01.733188Z","shell.execute_reply":"2022-06-06T03:48:02.455368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=64\ntrain_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\nval_loader = DataLoader(dataset=valid_dataset,batch_size=batch_size)\ntest_loader = DataLoader(dataset=test_dataset,batch_size=batch_size)\ndataloaders_dict ={'train':train_loader,'val':val_loader}\ndata = next(iter(test_loader))\nprint(data)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:02.457531Z","iopub.execute_input":"2022-06-06T03:48:02.457919Z","iopub.status.idle":"2022-06-06T03:48:02.745029Z","shell.execute_reply.started":"2022-06-06T03:48:02.457886Z","shell.execute_reply":"2022-06-06T03:48:02.744208Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Conv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, padding, stride=1, bias=True):\n        super(Conv2d, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n\nclass Reduction_A(nn.Module):\n    # 35 -> 17\n    def __init__(self, in_channels, k, l, m, n):\n        super(Reduction_A, self).__init__()\n        self.branch_0 = Conv2d(in_channels, n, 3, stride=2, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, k, 1, stride=1, padding=0, bias=False),\n            Conv2d(k, l, 3, stride=1, padding=1, bias=False),\n            Conv2d(l, m, 3, stride=2, padding=0, bias=False),\n        )\n        self.branch_2 = nn.MaxPool2d(3, stride=2, padding=0)\n\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        return torch.cat((x0, x1, x2), dim=1) # 17 x 17 x 1024","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:02.746539Z","iopub.execute_input":"2022-06-06T03:48:02.746968Z","iopub.status.idle":"2022-06-06T03:48:02.758228Z","shell.execute_reply.started":"2022-06-06T03:48:02.74693Z","shell.execute_reply":"2022-06-06T03:48:02.757426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Stem(nn.Module):\n    def __init__(self, in_channels):\n        super(Stem, self).__init__()\n        self.features = nn.Sequential(\n            Conv2d(in_channels, 32, 3, stride=2, padding=0, bias=False), # 149 x 149 x 32\n            Conv2d(32, 32, 3, stride=1, padding=0, bias=False), # 147 x 147 x 32\n            Conv2d(32, 64, 3, stride=1, padding=1, bias=False), # 147 x 147 x 64\n            nn.MaxPool2d(3, stride=2, padding=0), # 73 x 73 x 64\n            Conv2d(64, 80, 1, stride=1, padding=0, bias=False), # 73 x 73 x 80\n            Conv2d(80, 192, 3, stride=1, padding=0, bias=False), # 71 x 71 x 192\n            nn.MaxPool2d(3, stride=2, padding=0), # 35 x 35 x 192\n        )\n        self.branch_0 = Conv2d(192, 96, 1, stride=1, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(192, 48, 1, stride=1, padding=0, bias=False),\n            Conv2d(48, 64, 5, stride=1, padding=2, bias=False),\n        )\n        self.branch_2 = nn.Sequential(\n            Conv2d(192, 64, 1, stride=1, padding=0, bias=False),\n            Conv2d(64, 96, 3, stride=1, padding=1, bias=False),\n            Conv2d(96, 96, 3, stride=1, padding=1, bias=False),\n        )\n        self.branch_3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            Conv2d(192, 64, 1, stride=1, padding=0, bias=False)\n        )\n    def forward(self, x):\n        x = self.features(x)\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        x3 = self.branch_3(x)\n        return torch.cat((x0, x1, x2, x3), dim=1)\n\n\nclass Inception_ResNet_A(nn.Module):\n    def __init__(self, in_channels, scale=1.0):\n        super(Inception_ResNet_A, self).__init__()\n        self.scale = scale\n        self.branch_0 = Conv2d(in_channels, 32, 1, stride=1, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 32, 1, stride=1, padding=0, bias=False),\n            Conv2d(32, 32, 3, stride=1, padding=1, bias=False)\n        )\n        self.branch_2 = nn.Sequential(\n            Conv2d(in_channels, 32, 1, stride=1, padding=0, bias=False),\n            Conv2d(32, 48, 3, stride=1, padding=1, bias=False),\n            Conv2d(48, 64, 3, stride=1, padding=1, bias=False)\n        )\n        self.conv = nn.Conv2d(128, 320, 1, stride=1, padding=0, bias=True)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        x_res = torch.cat((x0, x1, x2), dim=1)\n        x_res = self.conv(x_res)\n        return self.relu(x + self.scale * x_res)\n\n\nclass Inception_ResNet_B(nn.Module):\n    def __init__(self, in_channels, scale=1.0):\n        super(Inception_ResNet_B, self).__init__()\n        self.scale = scale\n        self.branch_0 = Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 128, 1, stride=1, padding=0, bias=False),\n            Conv2d(128, 160, (1, 7), stride=1, padding=(0, 3), bias=False),\n            Conv2d(160, 192, (7, 1), stride=1, padding=(3, 0), bias=False)\n        )\n        self.conv = nn.Conv2d(384, 1088, 1, stride=1, padding=0, bias=True)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x_res = torch.cat((x0, x1), dim=1)\n        x_res = self.conv(x_res)\n        return self.relu(x + self.scale * x_res)\n\n\nclass Reduciton_B(nn.Module):\n    def __init__(self, in_channels):\n        super(Reduciton_B, self).__init__()\n        self.branch_0 = nn.Sequential(\n            Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False),\n            Conv2d(256, 384, 3, stride=2, padding=0, bias=False)\n        )\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False),\n            Conv2d(256, 288, 3, stride=2, padding=0, bias=False),\n        )\n        self.branch_2 = nn.Sequential(\n            Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False),\n            Conv2d(256, 288, 3, stride=1, padding=1, bias=False),\n            Conv2d(288, 320, 3, stride=2, padding=0, bias=False)\n        )\n        self.branch_3 = nn.MaxPool2d(3, stride=2, padding=0)\n\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        x3 = self.branch_3(x)\n        return torch.cat((x0, x1, x2, x3), dim=1)\n\n\nclass Inception_ResNet_C(nn.Module):\n    def __init__(self, in_channels, scale=1.0, activation=True):\n        super(Inception_ResNet_C, self).__init__()\n        self.scale = scale\n        self.activation = activation\n        self.branch_0 = Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False),\n            Conv2d(192, 224, (1, 3), stride=1, padding=(0, 1), bias=False),\n            Conv2d(224, 256, (3, 1), stride=1, padding=(1, 0), bias=False)\n        )\n        self.conv = nn.Conv2d(448, 2080, 1, stride=1, padding=0, bias=True)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x_res = torch.cat((x0, x1), dim=1)\n        x_res = self.conv(x_res)\n        if self.activation:\n            return self.relu(x + self.scale * x_res)\n        return x + self.scale * x_res\n\n\nclass Inception_ResNetv2(nn.Module):\n    def __init__(self, in_channels=3, classes=15, k=256, l=256, m=384, n=384):\n        super(Inception_ResNetv2, self).__init__()\n        blocks = []\n        blocks.append(Stem(in_channels))\n        for i in range(10):\n            blocks.append(Inception_ResNet_A(320, 0.17))\n        blocks.append(Reduction_A(320, k, l, m, n))\n        for i in range(20):\n            blocks.append(Inception_ResNet_B(1088, 0.10))\n        blocks.append(Reduciton_B(1088))\n        for i in range(9):\n            blocks.append(Inception_ResNet_C(2080, 0.20))\n        blocks.append(Inception_ResNet_C(2080, activation=False))\n        self.features = nn.Sequential(*blocks)\n        self.conv = Conv2d(2080, 1536, 1, stride=1, padding=0, bias=False)\n        self.global_average_pooling = nn.AdaptiveAvgPool2d((1, 1))\n        self.linear = nn.Linear(1536, classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.conv(x)\n        x = self.global_average_pooling(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:02.760327Z","iopub.execute_input":"2022-06-06T03:48:02.760612Z","iopub.status.idle":"2022-06-06T03:48:02.804116Z","shell.execute_reply.started":"2022-06-06T03:48:02.760576Z","shell.execute_reply":"2022-06-06T03:48:02.803249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Inception_ResNetv2().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:02.807167Z","iopub.execute_input":"2022-06-06T03:48:02.80738Z","iopub.status.idle":"2022-06-06T03:48:05.275044Z","shell.execute_reply.started":"2022-06-06T03:48:02.807348Z","shell.execute_reply":"2022-06-06T03:48:05.273266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Swish activation function\nclass Swish(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        return x * self.sigmoid(x)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.276279Z","iopub.execute_input":"2022-06-06T03:48:05.276558Z","iopub.status.idle":"2022-06-06T03:48:05.282663Z","shell.execute_reply.started":"2022-06-06T03:48:05.276521Z","shell.execute_reply":"2022-06-06T03:48:05.281742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SE Block\nclass SEBlock(nn.Module):\n    def __init__(self, in_channels, r=4):\n        super().__init__()\n\n        self.squeeze = nn.AdaptiveAvgPool2d((1,1))\n        self.excitation = nn.Sequential(\n            nn.Linear(in_channels, in_channels * r),\n            Swish(),\n            nn.Linear(in_channels * r, in_channels),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.squeeze(x)\n        x = x.view(x.size(0), -1)\n        x = self.excitation(x)\n        x = x.view(x.size(0), x.size(1), 1, 1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.285479Z","iopub.execute_input":"2022-06-06T03:48:05.285803Z","iopub.status.idle":"2022-06-06T03:48:05.294811Z","shell.execute_reply.started":"2022-06-06T03:48:05.285768Z","shell.execute_reply":"2022-06-06T03:48:05.293908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MBConv(nn.Module):\n    expand = 6\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n        super().__init__()\n        # first MBConv is not using stochastic depth\n        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n\n        self.residual = nn.Sequential(\n            nn.Conv2d(in_channels, in_channels * MBConv.expand, 1, stride=stride, padding=0, bias=False),\n            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n            Swish(),\n            nn.Conv2d(in_channels * MBConv.expand, in_channels * MBConv.expand, kernel_size=kernel_size,\n                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*MBConv.expand),\n            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n            Swish()\n        )\n\n        self.se = SEBlock(in_channels * MBConv.expand, se_scale)\n\n        self.project = nn.Sequential(\n            nn.Conv2d(in_channels*MBConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n        )\n\n        self.shortcut = (stride == 1) and (in_channels == out_channels)\n\n    def forward(self, x):\n        # stochastic depth\n        if self.training:\n            if not torch.bernoulli(self.p):\n                return x\n\n        x_shortcut = x\n        x_residual = self.residual(x)\n        x_se = self.se(x_residual)\n\n        x = x_se * x_residual\n        x = self.project(x)\n\n        if self.shortcut:\n            x= x_shortcut + x\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.296933Z","iopub.execute_input":"2022-06-06T03:48:05.29728Z","iopub.status.idle":"2022-06-06T03:48:05.313131Z","shell.execute_reply.started":"2022-06-06T03:48:05.297243Z","shell.execute_reply":"2022-06-06T03:48:05.312115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SepConv(nn.Module):\n    expand = 1\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n        super().__init__()\n        # first SepConv is not using stochastic depth\n        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n\n        self.residual = nn.Sequential(\n            nn.Conv2d(in_channels * SepConv.expand, in_channels * SepConv.expand, kernel_size=kernel_size,\n                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*SepConv.expand),\n            nn.BatchNorm2d(in_channels * SepConv.expand, momentum=0.99, eps=1e-3),\n            Swish()\n        )\n\n        self.se = SEBlock(in_channels * SepConv.expand, se_scale)\n\n        self.project = nn.Sequential(\n            nn.Conv2d(in_channels*SepConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n        )\n\n        self.shortcut = (stride == 1) and (in_channels == out_channels)\n\n    def forward(self, x):\n        # stochastic depth\n        if self.training:\n            if not torch.bernoulli(self.p):\n                return x\n\n        x_shortcut = x\n        x_residual = self.residual(x)\n        x_se = self.se(x_residual)\n\n        x = x_se * x_residual\n        x = self.project(x)\n\n        if self.shortcut:\n            x= x_shortcut + x\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.315238Z","iopub.execute_input":"2022-06-06T03:48:05.315811Z","iopub.status.idle":"2022-06-06T03:48:05.328652Z","shell.execute_reply.started":"2022-06-06T03:48:05.315772Z","shell.execute_reply":"2022-06-06T03:48:05.3278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EfficientNet(nn.Module):\n    def __init__(self, num_classes=10, width_coef=1., depth_coef=1., scale=1., dropout=0.2, se_scale=4, stochastic_depth=False, p=0.5):\n        super().__init__()\n        channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n        repeats = [1, 2, 2, 3, 3, 4, 1]\n        strides = [1, 2, 2, 2, 1, 2, 1]\n        kernel_size = [3, 3, 5, 3, 5, 5, 3]\n        depth = depth_coef\n        width = width_coef\n\n        channels = [int(x*width) for x in channels]\n        repeats = [int(x*depth) for x in repeats]\n\n        # stochastic depth\n        if stochastic_depth:\n            self.p = p\n            self.step = (1 - 0.5) / (sum(repeats) - 1)\n        else:\n            self.p = 1\n            self.step = 0\n\n\n        # efficient net\n        self.upsample = nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False)\n\n        self.stage1 = nn.Sequential(\n            nn.Conv2d(3, channels[0],3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(channels[0], momentum=0.99, eps=1e-3)\n        )\n\n        self.stage2 = self._make_Block(SepConv, repeats[0], channels[0], channels[1], kernel_size[0], strides[0], se_scale)\n\n        self.stage3 = self._make_Block(MBConv, repeats[1], channels[1], channels[2], kernel_size[1], strides[1], se_scale)\n\n        self.stage4 = self._make_Block(MBConv, repeats[2], channels[2], channels[3], kernel_size[2], strides[2], se_scale)\n\n        self.stage5 = self._make_Block(MBConv, repeats[3], channels[3], channels[4], kernel_size[3], strides[3], se_scale)\n\n        self.stage6 = self._make_Block(MBConv, repeats[4], channels[4], channels[5], kernel_size[4], strides[4], se_scale)\n\n        self.stage7 = self._make_Block(MBConv, repeats[5], channels[5], channels[6], kernel_size[5], strides[5], se_scale)\n\n        self.stage8 = self._make_Block(MBConv, repeats[6], channels[6], channels[7], kernel_size[6], strides[6], se_scale)\n\n        self.stage9 = nn.Sequential(\n            nn.Conv2d(channels[7], channels[8], 1, stride=1, bias=False),\n            nn.BatchNorm2d(channels[8], momentum=0.99, eps=1e-3),\n            Swish()\n        ) \n\n        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        self.dropout = nn.Dropout(p=dropout)\n        self.linear = nn.Linear(channels[8], num_classes)\n\n    def forward(self, x):\n        x = self.upsample(x)\n        x = self.stage1(x)\n        x = self.stage2(x)\n        x = self.stage3(x)\n        x = self.stage4(x)\n        x = self.stage5(x)\n        x = self.stage6(x)\n        x = self.stage7(x)\n        x = self.stage8(x)\n        x = self.stage9(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        x = self.linear(x)\n        return x\n\n\n    def _make_Block(self, block, repeats, in_channels, out_channels, kernel_size, stride, se_scale):\n        strides = [stride] + [1] * (repeats - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(in_channels, out_channels, kernel_size, stride, se_scale, self.p))\n            in_channels = out_channels\n            self.p -= self.step\n\n        return nn.Sequential(*layers)\n\n\ndef efficientnet_b0(num_classes=15):\n    return EfficientNet(num_classes=num_classes, width_coef=1.0, depth_coef=1.0, scale=1.0,dropout=0.2, se_scale=4)\n\ndef efficientnet_b1(num_classes=15):\n    return EfficientNet(num_classes=num_classes, width_coef=1.0, depth_coef=1.1, scale=240/224, dropout=0.2, se_scale=4)\n\ndef efficientnet_b2(num_classes=15):\n    return EfficientNet(num_classes=num_classes, width_coef=1.1, depth_coef=1.2, scale=260/224., dropout=0.3, se_scale=4)\n\ndef efficientnet_b3(num_classes=15):\n    return EfficientNet(num_classes=num_classes, width_coef=1.2, depth_coef=1.4, scale=300/224, dropout=0.3, se_scale=4)\n\ndef efficientnet_b4(num_classes=15):\n    return EfficientNet(num_classes=num_classes, width_coef=1.4, depth_coef=1.8, scale=380/224, dropout=0.4, se_scale=4)\n\ndef efficientnet_b5(num_classes=15):\n    return EfficientNet(num_classes=num_classes, width_coef=1.6, depth_coef=2.2, scale=456/224, dropout=0.4, se_scale=4)\n\ndef efficientnet_b6(num_classes=15):\n    return EfficientNet(num_classes=num_classes, width_coef=1.8, depth_coef=2.6, scale=528/224, dropout=0.5, se_scale=4)\n\ndef efficientnet_b7(num_classes=15):\n    return EfficientNet(num_classes=num_classes, width_coef=2.0, depth_coef=3.1, scale=600/224, dropout=0.5, se_scale=4)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.332977Z","iopub.execute_input":"2022-06-06T03:48:05.333222Z","iopub.status.idle":"2022-06-06T03:48:05.365251Z","shell.execute_reply.started":"2022-06-06T03:48:05.333184Z","shell.execute_reply":"2022-06-06T03:48:05.36446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 파이토치\nimport torch\n\n# 파이토치 레이어 정의를 위한 torch.nn\nimport torch.nn as nn\n\n# activation func 사용을 위한 nn.functional\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.367577Z","iopub.execute_input":"2022-06-06T03:48:05.367822Z","iopub.status.idle":"2022-06-06T03:48:05.37632Z","shell.execute_reply.started":"2022-06-06T03:48:05.367794Z","shell.execute_reply":"2022-06-06T03:48:05.375501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n\t# mul은 추후 ResNet18, 34, 50, 101, 152등 구조 생성에 사용됨\n    mul = 1\n    def __init__(self, in_planes, out_planes, stride=1):\n        super(BasicBlock, self).__init__()\n        \n        # stride를 통해 너비와 높이 조정\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_planes)\n        \n        # stride = 1, padding = 1이므로, 너비와 높이는 항시 유지됨\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        \n        # x를 그대로 더해주기 위함\n        self.shortcut = nn.Sequential()\n        \n        # 만약 size가 안맞아 합연산이 불가하다면, 연산 가능하도록 모양을 맞춰줌\n        if stride != 1: # x와 \n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_planes)\n            )\n    \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = F.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += self.shortcut(x) # 필요에 따라 layer를 Skip\n        out = F.relu(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.377422Z","iopub.execute_input":"2022-06-06T03:48:05.377662Z","iopub.status.idle":"2022-06-06T03:48:05.389729Z","shell.execute_reply.started":"2022-06-06T03:48:05.377629Z","shell.execute_reply":"2022-06-06T03:48:05.388823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BottleNeck(nn.Module):\n\t# 논문의 구조를 참고하여 mul 값은 4로 지정, 즉, 64 -> 256\n    mul = 4\n    def __init__(self, in_planes, out_planes, stride=1):\n        super(BottleNeck, self).__init__()\n        \n        #첫 Convolution은 너비와 높이 downsampling\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_planes)\n        \n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        \n        self.conv3 = nn.Conv2d(out_planes, out_planes*self.mul, kernel_size=1, stride=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_planes*self.mul)\n        \n        self.shortcut = nn.Sequential()\n        \n        if stride != 1 or in_planes != out_planes*self.mul:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, out_planes*self.mul, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_planes*self.mul)\n            )\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = F.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = F.relu(out)\n        out = self.conv3(out)\n        out = self.bn3(out)\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.391253Z","iopub.execute_input":"2022-06-06T03:48:05.391596Z","iopub.status.idle":"2022-06-06T03:48:05.406285Z","shell.execute_reply.started":"2022-06-06T03:48:05.391562Z","shell.execute_reply":"2022-06-06T03:48:05.405383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n\t# Paint set을 학습시킬 것이므로, num_classes=15으로 설정\n    def __init__(self, block, num_blocks, num_classes=15):\n        super(ResNet, self).__init__()\n        #RGB 3개채널에서 64개의 Kernel 사용 (논문 참고)\n        self.in_planes = 64\n        \n        # Resnet 논문 구조의 conv1 파트 그대로 구현\n        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=7, stride=2, padding = 3)\n        self.bn1 = nn.BatchNorm2d(self.in_planes)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        \n        self.layer1 = self.make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self.make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self.make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self.make_layer(block, 512, num_blocks[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        \n        # Basic Resiudal Block일 경우 그대로, BottleNeck일 경우 4를 곱한다.\n        self.linear = nn.Linear(512 * block.mul, num_classes)\n        \n    # 다양한 Architecture 생성을 위해 make_layer로 Sequential 생성     \n    def make_layer(self, block, out_planes, num_blocks, stride):\n        # layer 앞부분에서만 크기를 절반으로 줄이므로, 아래와 같은 구조\n        strides = [stride] + [1] * (num_blocks-1)\n        layers = []\n        for i in range(num_blocks):\n            layers.append(block(self.in_planes, out_planes, strides[i]))\n            self.in_planes = block.mul * out_planes\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = F.relu(out)\n        out = self.maxpool1(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avgpool(out)\n        out = torch.flatten(out,1)\n        out = self.linear(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.408528Z","iopub.execute_input":"2022-06-06T03:48:05.408716Z","iopub.status.idle":"2022-06-06T03:48:05.424635Z","shell.execute_reply.started":"2022-06-06T03:48:05.408687Z","shell.execute_reply":"2022-06-06T03:48:05.423643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ResNet18():\n    return ResNet(BasicBlock, [2, 2, 2, 2])\n\ndef ResNet34():\n    return ResNet(BasicBlock, [3, 4, 6, 3])\n\ndef ResNet50():\n    return ResNet(BottleNeck, [3, 4, 6, 3])\n\ndef ResNet101():\n    return ResNet(BottleNeck, [3, 4, 23, 3])\n\ndef ResNet152():\n    return ResNet(BottleNeck, [3, 8, 36, 3])","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.426899Z","iopub.execute_input":"2022-06-06T03:48:05.427398Z","iopub.status.idle":"2022-06-06T03:48:05.435359Z","shell.execute_reply.started":"2022-06-06T03:48:05.427361Z","shell.execute_reply":"2022-06-06T03:48:05.43451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:05.436793Z","iopub.execute_input":"2022-06-06T03:48:05.437058Z","iopub.status.idle":"2022-06-06T03:48:06.213711Z","shell.execute_reply.started":"2022-06-06T03:48:05.437024Z","shell.execute_reply":"2022-06-06T03:48:06.212681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = ResNet50().to(device)\n\nx = torch.randn(3, 3, 224, 224).to(device)\noutput = model(x)\n#print(output.size())","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:06.215283Z","iopub.execute_input":"2022-06-06T03:48:06.215878Z","iopub.status.idle":"2022-06-06T03:48:07.422149Z","shell.execute_reply.started":"2022-06-06T03:48:06.215835Z","shell.execute_reply":"2022-06-06T03:48:07.421388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_func = nn.CrossEntropyLoss(reduction='sum')\nopt = optim.Adam(model.parameters(), lr=0.001)\n\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nlr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:07.423286Z","iopub.execute_input":"2022-06-06T03:48:07.423564Z","iopub.status.idle":"2022-06-06T03:48:07.432242Z","shell.execute_reply.started":"2022-06-06T03:48:07.42353Z","shell.execute_reply":"2022-06-06T03:48:07.43135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to get current lr\ndef get_lr(opt):\n    for param_group in opt.param_groups:\n        return param_group['lr']\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:07.434323Z","iopub.execute_input":"2022-06-06T03:48:07.434893Z","iopub.status.idle":"2022-06-06T03:48:07.440081Z","shell.execute_reply.started":"2022-06-06T03:48:07.434856Z","shell.execute_reply":"2022-06-06T03:48:07.439412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to calculate metric per mini-batch\ndef metric_batch(output, target):\n    pred = output.argmax(1, keepdim=True)\n    corrects = pred.eq(target.view_as(pred)).sum().item()\n    return corrects\n\n\n# function to calculate loss per mini-batch\ndef loss_batch(loss_func, output, target, opt=None):\n    loss = loss_func(output, target)\n    metric_b = metric_batch(output, target)\n\n    if opt is not None:\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n    return loss.item(), metric_b","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:07.441305Z","iopub.execute_input":"2022-06-06T03:48:07.442012Z","iopub.status.idle":"2022-06-06T03:48:07.449947Z","shell.execute_reply.started":"2022-06-06T03:48:07.441971Z","shell.execute_reply":"2022-06-06T03:48:07.44907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to calculate loss and metric per epoch\ndef loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n    running_loss = 0.0\n    running_metric = 0.0\n    len_data = len(dataset_dl.dataset)\n\n    for xb, yb in tqdm(dataset_dl):\n        xb = xb.to(device)\n        yb = yb.to(device)\n        output = model(xb)\n\n        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n\n        running_loss += loss_b\n        \n        if metric_b is not None:\n            running_metric += metric_b\n        \n        if sanity_check is True:\n            break\n\n    loss = running_loss / len_data\n    metric = running_metric / len_data\n\n    return loss, metric","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:07.451092Z","iopub.execute_input":"2022-06-06T03:48:07.451771Z","iopub.status.idle":"2022-06-06T03:48:07.46063Z","shell.execute_reply.started":"2022-06-06T03:48:07.451736Z","shell.execute_reply":"2022-06-06T03:48:07.459872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to start training\ndef train_val(model, params):\n    num_epochs=params['num_epochs']\n    loss_func=params[\"loss_func\"]\n    opt=params[\"optimizer\"]\n    train_dl=params[\"train_dl\"]\n    val_dl=params[\"val_dl\"]\n    sanity_check=params[\"sanity_check\"]\n    lr_scheduler=params[\"lr_scheduler\"]\n    path2weights=params[\"path2weights\"]\n\n    loss_history = {'train': [], 'val': []}\n    metric_history = {'train': [], 'val': []}\n\n    # # GPU out of memoty error\n    # best_model_wts = copy.deepcopy(model.state_dict())\n\n    best_loss = float('inf')\n\n    start_time = time.time()\n\n    for epoch in range(num_epochs):\n        current_lr = get_lr(opt)\n        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs-1, current_lr))\n\n        model.train()\n        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n        loss_history['train'].append(train_loss)\n        metric_history['train'].append(train_metric)\n\n        model.eval()\n        with torch.no_grad():\n            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n        loss_history['val'].append(val_loss)\n        metric_history['val'].append(val_metric)\n\n        if val_loss < best_loss:\n            best_loss = val_loss\n            #best_model_wts = copy.deepcopy(model.state_dict())\n\n            #torch.save(model.state_dict(), path2weights)\n            torch.save(model, path2weights)\n            # print('Copied best model weights!')\n            print('Get best val_loss')\n\n        lr_scheduler.step(val_loss)\n\n        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n        print('-'*10)\n\n    #model=model.load_state_dict(best_model_wts)\n\n    return model, loss_history, metric_history","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:07.462599Z","iopub.execute_input":"2022-06-06T03:48:07.462855Z","iopub.status.idle":"2022-06-06T03:48:07.479034Z","shell.execute_reply.started":"2022-06-06T03:48:07.462823Z","shell.execute_reply":"2022-06-06T03:48:07.478308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# definc the training parameters\nparams_train = {\n    'num_epochs':40,\n    'optimizer':opt,\n    'loss_func':loss_func,\n    'train_dl':train_loader,\n    'val_dl':val_loader,\n    'sanity_check':False,\n    'lr_scheduler':lr_scheduler,\n    'path2weights':'./models/weights2.pt',\n}\n\n# create the directory that stores weights.pt\ndef createFolder(directory):\n    try:\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n    except OSerror:\n        print('Error')\ncreateFolder('./models')","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:07.480371Z","iopub.execute_input":"2022-06-06T03:48:07.480847Z","iopub.status.idle":"2022-06-06T03:48:07.492177Z","shell.execute_reply.started":"2022-06-06T03:48:07.480735Z","shell.execute_reply":"2022-06-06T03:48:07.491491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:07.493895Z","iopub.execute_input":"2022-06-06T03:48:07.494305Z","iopub.status.idle":"2022-06-06T03:48:16.846375Z","shell.execute_reply.started":"2022-06-06T03:48:07.494268Z","shell.execute_reply":"2022-06-06T03:48:16.845514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = ResNet34().to(device)\n#model","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:16.849792Z","iopub.execute_input":"2022-06-06T03:48:16.85002Z","iopub.status.idle":"2022-06-06T03:48:16.856076Z","shell.execute_reply.started":"2022-06-06T03:48:16.849992Z","shell.execute_reply":"2022-06-06T03:48:16.855328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, loss_hist, metric_hist = train_val(model, params_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T03:48:16.858815Z","iopub.execute_input":"2022-06-06T03:48:16.859038Z","iopub.status.idle":"2022-06-06T04:04:01.848762Z","shell.execute_reply.started":"2022-06-06T03:48:16.859014Z","shell.execute_reply":"2022-06-06T04:04:01.847923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = []\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X in dataloader:\n            X = X.to(device)\n            pred = model(X)\n            print(pred.argmax(1))\n            for p in pred:\n                labels.append(p.argmax(0).item())\n            ","metadata":{"execution":{"iopub.status.busy":"2022-06-06T04:04:01.850205Z","iopub.execute_input":"2022-06-06T04:04:01.850741Z","iopub.status.idle":"2022-06-06T04:04:01.859373Z","shell.execute_reply.started":"2022-06-06T04:04:01.850701Z","shell.execute_reply":"2022-06-06T04:04:01.858504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test(test_loader,model, loss_func)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T04:04:01.864167Z","iopub.execute_input":"2022-06-06T04:04:01.86459Z","iopub.status.idle":"2022-06-06T04:04:05.901004Z","shell.execute_reply.started":"2022-06-06T04:04:01.864525Z","shell.execute_reply":"2022-06-06T04:04:05.900242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(painters)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T04:04:05.902439Z","iopub.execute_input":"2022-06-06T04:04:05.902693Z","iopub.status.idle":"2022-06-06T04:04:05.908253Z","shell.execute_reply.started":"2022-06-06T04:04:05.902659Z","shell.execute_reply":"2022-06-06T04:04:05.907375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pictures = glob.glob('../input/paint-dataset/painting_resize_256/test/*.jpg')\nfor i in range(len(pictures)):\n    pictures[i] = pictures[i].split('/')[-1]\npictures.sort()    ","metadata":{"execution":{"iopub.status.busy":"2022-06-06T04:04:05.90977Z","iopub.execute_input":"2022-06-06T04:04:05.910293Z","iopub.status.idle":"2022-06-06T04:04:05.922438Z","shell.execute_reply.started":"2022-06-06T04:04:05.910254Z","shell.execute_reply":"2022-06-06T04:04:05.921753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answers = []\nfor l in labels:\n    answers.append(painters[l])\nprint(answers)    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-06T04:04:05.923696Z","iopub.execute_input":"2022-06-06T04:04:05.924032Z","iopub.status.idle":"2022-06-06T04:04:05.929102Z","shell.execute_reply.started":"2022-06-06T04:04:05.923995Z","shell.execute_reply":"2022-06-06T04:04:05.928273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer_df = pd.DataFrame()\nanswer_df['id'] = pictures\nanswer_df['Category'] = answers\nanswer_df.to_csv('./Submission_1.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T04:04:05.930219Z","iopub.execute_input":"2022-06-06T04:04:05.930403Z","iopub.status.idle":"2022-06-06T04:04:05.946665Z","shell.execute_reply.started":"2022-06-06T04:04:05.930381Z","shell.execute_reply":"2022-06-06T04:04:05.945933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}